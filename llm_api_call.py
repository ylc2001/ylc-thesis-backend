from handyllm import OpenAIClient
from handyllm import PromptConverter, stream_chat
import os
import json
import yaml
from zhipuai import ZhipuAI

# 说明：如果测试新的题目数据，输入要放到step_1最下面，$user$里面
# 之后的过程是自动化的
# 万一最后格式有问题没有输出到json文件，去终端拷贝输出手动搞
# 每一步耗时在 30s 左右，总流程一分半，别急

input_folder = "input_data_yaml"
input_filename = "0424_cwh_correct.yaml"
input_path = os.path.join(os.getcwd(), input_folder, input_filename)

with open('config.yaml', 'r') as file:
	config = yaml.safe_load(file)
with open(input_path, 'r') as file:
	input_data = yaml.safe_load(file)

# input_data: problem, think_aloud, written_text; audio_text

# promt 文件存在 ./dir_name/step_x.txt
dir_name = "prompts"
audio_text_promt = "audio_text.txt"
step_1 = "1_action_list.txt"
step_2 = "2_memory.txt"
step_3 = "3_computation_graph.txt"
step_6 = "6_standardize.txt"

def call_azure_api(chat):
	'''
	chat: list, chat format generated by PromptConverter

	return: str, response from Azure API
	'''
	with OpenAIClient(
		api_key=config["azure_api_key"], 
		api_base='https://pcg-west-us.openai.azure.com/', 
		api_type='azure', 
		api_version='2023-12-01-preview'  # 这个是哪来的？不敢动
		) as client:
		response = client.chat(
			model="gpt-4-1106-preview",  # 注意模型名字是azure里定义的名字，不一定是这个
			messages=chat,
			stream=True
			# response_format={ "type": "json_object" }, 
		).call()  ## note .call() here
		result = ""
		print("---------- Azure API response ----------")
		for text in stream_chat(response):
			result += text
			print(text, end='')
		print("\n----------------------------------------")
		return result
	
def call_glm_api(chat):
	client = ZhipuAI(api_key=config["zhipuai_api_key"])
	response = client.chat.completions.create(
            model="glm-4",  # 填写需要调用的模型名称
            messages=chat,
            stream=True,
        )
	result = ""
	print("---------- ChatGLM API response ----------")
	for (i, chunk) in enumerate(response):
		result += chunk.choices[0].delta.content
		print(chunk.choices[0].delta.content, end='')
	print("\n----------------------------------------")
	return result


converter = PromptConverter()

if "audio_text" in input_data:
	print(">>> Using existing [fixed audio_text] <<<")
else:
	chat_audio = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, audio_text_promt))
	chat_audio[-1]["content"] = chat_audio[-1]["content"].replace("%think_aloud%", input_data["think_aloud"])
	print(">>> FIX AUDIO TEXT <<<")
	input_data["audio_text"] = call_azure_api(chat_audio)
	# input_data["audio_text"] = call_glm_api(chat_audio)

if "action_list" in input_data:
	print(">>> Using existing [action list] <<<")
else:
	chat_1 = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, step_1))
	chat_1[-1]["content"] = chat_1[-1]["content"].replace("%problem%", input_data["problem"])
	chat_1[-1]["content"] = chat_1[-1]["content"].replace("%audio_text%", input_data["audio_text"])
	chat_1[-1]["content"] = chat_1[-1]["content"].replace("%written_text%", input_data["written_text"])
	print(">>> Step 1 action_list <<<")
	# input_data["action_list"] = call_glm_api(chat_1)
	input_data["action_list"] = call_azure_api(chat_1)

if "memory" in input_data:
	print(">>> Using existing [memory] <<<")
else:
	chat_2 = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, step_2))
	chat_2[-1]["content"] = chat_2[-1]["content"].replace("%problem%", input_data["problem"])
	chat_2[-1]["content"] = chat_2[-1]["content"].replace("%audio_text%", input_data["audio_text"])
	chat_2[-1]["content"] = chat_2[-1]["content"].replace("%written_text%", input_data["written_text"])
	chat_2[-1]["content"] = chat_2[-1]["content"].replace("%action_list%", input_data["action_list"])
	print(">>> Step 2 memory <<<")
	# input_data["memory"] = call_glm_api(chat_1)
	input_data["memory"] = call_azure_api(chat_2)

if "student_graph" in input_data:
	print(">>> Using existing [student_graph] <<<")
else:
	chat_3 = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, step_3))
	chat_3[-1]["content"] = chat_3[-1]["content"].replace("%problem%", input_data["problem"])
	chat_3[-1]["content"] = chat_3[-1]["content"].replace("%audio_text%", input_data["audio_text"])
	chat_3[-1]["content"] = chat_3[-1]["content"].replace("%written_text%", input_data["written_text"])
	chat_3[-1]["content"] = chat_3[-1]["content"].replace("%memory%", input_data["memory"])
	print(">>> Step 3 student_graph <<<")
	# input_data["memory"] = call_glm_api(chat_1)
	input_data["student_graph"] = call_azure_api(chat_3)

output_json_path = os.path.join(os.getcwd(), "results", input_filename+"_graph.json")
with open(output_json_path, 'w') as file:
	try:
		json.dump(json.loads(input_data["student_graph"]), file, indent=4, ensure_ascii=False)
		print(f">>> Graph results saved to json file.")
	except Exception as e:
		print("!! Graph result is not a json string.")
		print(e)


# if "student_graph_std" in input_data:
# 	print(">>> Using existing [student_graph_std] <<<")
# else:
standard_graph = json.load(open(os.path.join(os.getcwd(), "results", "standard_graph.json"), 'r'))
standard_graph_str = json.dumps(standard_graph, indent=4, ensure_ascii=False)
chat_6 = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, step_6))
chat_6[-1]["content"] = chat_6[-1]["content"].replace("%student_graph%", input_data["student_graph"])
chat_6[-1]["content"] = chat_6[-1]["content"].replace("%standard_graph%", standard_graph_str)
print(">>> Step 6 student_graph_std <<<")
print(chat_6)
# input_data["memory"] = call_glm_api(chat_1)
input_data["student_graph_std"] = call_azure_api(chat_6)

output_json_path = os.path.join(os.getcwd(), "results", input_filename+"_graph_std.json")
with open(output_json_path, 'w') as file:
	try:
		json.dump(json.loads(input_data["student_graph_std"]), file, indent=4, ensure_ascii=False)
		print(f">>> Graph results saved to json file.")
	except Exception as e:
		print("!! Graph result is not a json string.")
		print(e)





# write into yaml file
with open(input_path, 'w') as file:
	yaml.dump(input_data, file, default_flow_style=False, allow_unicode=True)
	print(f">>> results saved to yaml file.")


# # print(json.dumps(chat, indent=4, ensure_ascii=False))
# print(">>> ROUND 1 <<<")
# res_1 = call_azure_api(chat_1)

# following_input = """
# [题目]
# 已知函数 $f(x)=a\left(\mathrm{e}^x+a\right)-x$.
# (1) 讨论 $f(x)$ 的单调性：
# (2) 证明：当 $a>0$ 时, $f(x)>2 \ln a+\frac{3}{2}$.

# [解题过程]
# """

# input_2 = following_input + res_1
# file_path_2 = os.path.join(os.getcwd(), dir_name, step_2)
# chat_2 = converter.rawfile2chat(file_path_2)
# chat_2.append({"role": "user", "content": input_2})
# print(">>> ROUND 2 <<<")
# res_2 = call_azure_api(chat_2)

# input_3 = following_input + res_2
# file_path_3 = os.path.join(os.getcwd(), dir_name, step_3)
# chat_3 = converter.rawfile2chat(file_path_3)
# chat_3.append({"role": "user", "content": input_3})
# print(">>> ROUND 3 <<<")
# res_3 = call_azure_api(chat_3)

# try :
# 	res_3_dict = json.loads(res_3)
# except Exception as e:
# 	print("!! Final result is not a json string.")
# 	print(e)
# 	exit(1)

# # save res_3 to ./promts/test.json
# with open(os.path.join(os.getcwd(), dir_name, "test.json"), 'w') as file:
# 	json.dump(res_3_dict, file, indent=4, ensure_ascii=False)
# 	print(f">>> Result saved to json file.")

