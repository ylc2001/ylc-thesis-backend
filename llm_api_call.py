from handyllm import OpenAIClient
from handyllm import PromptConverter, stream_chat
import os
import json
import yaml
from zhipuai import ZhipuAI
import textwrap
import time
import copy


# 说明：如果测试新的题目数据，输入要放到step_1最下面，$user$里面
# 之后的过程是自动化的
# 万一最后格式有问题没有输出到json文件，去终端拷贝输出手动搞
# 每一步耗时在 30s 左右，总流程一分半，别急

input_folder = "input_data_yaml"
input_filename = "0506_DengHaiping"
thinkaloud_chunk = False 	         # 原始的语音转文字文本是否分段处理
llm_api_name = "azure"               # "azure", "openai", "glm"
use_existing_data_yaml = True        # 是否使用 yaml 文件中已有的中间结果

# print thest parameters
print(">>> Parameters <<<")
print(f"input_dir: {input_folder}/{input_filename}.yaml")
print(f"llm_api_name: {llm_api_name}")

std_graph_path = os.path.join(os.getcwd(), input_folder, "0506_std_graph.json")
input_path = os.path.join(os.getcwd(), input_folder, input_filename+".yaml")
cache_path = os.path.join(os.getcwd(), input_folder, input_filename+"_cache.yaml")

with open('credential.yaml', 'r') as file:
	config = yaml.safe_load(file)
with open(input_path, 'r') as file:
	input_data = yaml.safe_load(file)
# if cache_path exists, load it
# if os.path.exists(cache_path) and use_existing_data_yaml:
# 	with open(cache_path, 'r') as file:
# 		input_data = yaml.safe_load(file)
with open(std_graph_path, 'r') as json_file:
	standard_graph_json = json.load(json_file)
	standard_graph = json.dumps(standard_graph_json, ensure_ascii=False)

# input_data: problem, think_aloud, written_text; audio_text

# promt 文件存在 ./dir_name/step_x.txt
dir_name = "prompts"
audio_text_promt = "audio_text.txt"
step_1 = "check_node_correctness.hprompt"

def call_llm_api(chat: list, api_name: str, json_format=False):
	'''
	chat: list, chat format generated by PromptConverter

	api_name: str, "azure", "openai", "glm"

	return: str, response from Azure API
	'''

	while True:
		try:
			if api_name == "azure":
				with OpenAIClient(
					api_key=config["azure_api_key"], 
					api_base='https://pcg-west-us.openai.azure.com/', 
					api_type='azure', 
					api_version='2023-12-01-preview'  # 这个是哪来的？不敢动
					) as client:
					response = client.chat(
						model="gpt-4-1106-preview",  # 注意模型名字是azure里定义的名字，不一定是这个
						messages=chat,
						stream=True,
						response_format={ "type": "json_object" if json_format else "text"},
						temperature=0.2,
					).call()  ## note .call() here
					result = ""
					print("---------- Azure API response ----------")
					for text in stream_chat(response):
						result += text
						print(text, end='')
					print("\n----------------------------------------")
					return result
			elif api_name == "openai":
				with OpenAIClient(
					api_key=config["openai_api_key"],  
					organization=config["openai_organization"],
					) as client:
					response = client.chat(
						model="gpt-4-1106-preview",  # 注意模型名字是azure里定义的名字，不一定是这个
						messages=chat,
						stream=True,
						response_format={ "type": "json_object" if json_format else "text"},
						temperature=0.2,
					).call()  ## note .call() here
					result = ""
					print("---------- OpenAI API response ----------")
					for text in stream_chat(response):
						result += text
						print(text, end='')
					print("\n----------------------------------------")
					return result
			elif api_name == "glm":
				client = ZhipuAI(api_key=config["zhipuai_api_key"])
				response = client.chat.completions.create(
						model="glm-4",  # 填写需要调用的模型名称
						messages=chat,
						stream=True,
					)
				result = ""
				print("---------- ChatGLM API response ----------")
				for (i, chunk) in enumerate(response):
					result += chunk.choices[0].delta.content
					print(chunk.choices[0].delta.content, end='')
				print("\n----------------------------------------")
				return result
			else:
				print("API name not recognized.")
				break
		except Exception as e:
			print(f"API调用失败，错误信息：{e}。5秒后重试。")
			time.sleep(5)  # 等待5秒再次尝试
	

converter = PromptConverter()

if "audio_text" in input_data and use_existing_data_yaml:
	print(">>> Using existing [fixed audio_text] <<<")
else:
	chat_audio = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, audio_text_promt))
	if thinkaloud_chunk:
		think_aloud_parts = textwrap.wrap(input_data["think_aloud"], 500)
		results = []
		for part in think_aloud_parts:
			print(part)
			chat_audio = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, audio_text_promt))
			chat_audio[-1]["content"] = chat_audio[-1]["content"].replace("%think_aloud%", part)
			print(">>> FIX AUDIO TEXT (part) <<<")
			result = call_llm_api(chat_audio, llm_api_name)
			results.append(result)
		input_data["audio_text"] = "".join(results)
	else:
		chat_audio[-1]["content"] = chat_audio[-1]["content"].replace("%think_aloud%", input_data["think_aloud"])
		print(">>> FIX AUDIO TEXT <<<")
		input_data["audio_text"] = call_llm_api(chat_audio, llm_api_name)


chat_1 = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, step_1))
chat_1[-1]["content"] = chat_1[-1]["content"].replace("%problem%", input_data["problem"])
chat_1[-1]["content"] = chat_1[-1]["content"].replace("%audio_text%", input_data["audio_text"])
chat_1[-1]["content"] = chat_1[-1]["content"].replace("%written_text%", input_data["written_text"])
chat_1[-1]["content"] = chat_1[-1]["content"].replace("%standard_graph%", standard_graph)
result_list = []
for item in standard_graph_json['nodes']:
	if item['id'] < 1000:
	# if item['id'] == 18:
		chat_1_copy = copy.deepcopy(chat_1)
		print(f">>> 节点 {item['id']} 判断 & 错因分析 <<<")
		print("---------------------------------------")
		chat_1_copy[-1]["content"] = chat_1_copy[-1]["content"].replace("%node_id%", f"{item['id']}")
		chat_1_copy[-1]["content"] = chat_1_copy[-1]["content"].replace("%node_content%", f"{item['content']}")
		converter.chat2rawfile(chat_1_copy, "temp.txt")
		res = call_llm_api(chat_1_copy, llm_api_name, True)
		result_list.append(json.loads(res))

# save reuslt list
current_time_str = time.strftime("%H%M%S", time.localtime())
with open(os.path.join(os.getcwd(), "results", current_time_str + input_filename+"_result.json"), 'w') as file:
	json.dump(result_list, file, ensure_ascii=False, indent=4)
	print(f"Saved result to {input_filename}_result.json")






