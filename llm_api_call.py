from handyllm import OpenAIClient
from handyllm import PromptConverter, stream_chat
import os
import json
import yaml
from zhipuai import ZhipuAI

# 说明：如果测试新的题目数据，输入要放到step_1最下面，$user$里面
# 之后的过程是自动化的
# 万一最后格式有问题没有输出到json文件，去终端拷贝输出手动搞
# 每一步耗时在 30s 左右，总流程一分半，别急

with open('config.yaml', 'r') as file:
	config = yaml.safe_load(file)
with open('__input.yaml', 'r') as file:
	input_data = yaml.safe_load(file)
# promt 文件存在 ./dir_name/step_x.txt
audio_text_promt = "audio_text.txt"
step_1 = "step-1-v3.txt"
step_2 = "step-2-v2.txt"
step_3 = "step-3-v3.txt"
dir_name = "prompts"

def call_azure_api(chat):
	'''
	chat: list, chat format generated by PromptConverter

	return: str, response from Azure API
	'''
	with OpenAIClient(
		api_key=config["azure_api_key"], 
		api_base='https://pcg-west-us.openai.azure.com/', 
		api_type='azure', 
		api_version='2023-12-01-preview'  # 这个是哪来的？不敢动
		) as client:
		response = client.chat(
			model="gpt-4-1106-preview",  # 注意模型名字是azure里定义的名字，不一定是这个
			messages=chat,
			stream=True
			# response_format={ "type": "json_object" }, 
		).call()  ## note .call() here
		result = ""
		print("---------- Azure API response ----------")
		for text in stream_chat(response):
			result += text
			print(text, end='')
		print("\n----------------------------------------")
		return result
	
def call_glm_api(chat):
	client = ZhipuAI(api_key=config["zhipuai_api_key"])
	response = client.chat.completions.create(
            model="glm-4",  # 填写需要调用的模型名称
            messages=chat,
            stream=True,
        )
	result = ""
	print("---------- ChatGLM API response ----------")
	for (i, chunk) in enumerate(response):
		result += chunk.choices[0].delta.content
		print(chunk.choices[0].delta.content, end='')
	print("\n----------------------------------------")
	return result
        

converter = PromptConverter()
chat_audio = converter.rawfile2chat(os.path.join(os.getcwd(), dir_name, audio_text_promt))
chat_audio[1]["content"] += input_data["think_aloud"]
print(json.dumps(chat_audio, indent=4, ensure_ascii=False))
print(">>> FIX AUDIO TEXT <<<")
# fixed_audio_text = call_azure_api(chat_audio)
fixed_audio_text = call_glm_api(chat_audio)

# file_path_1 = os.path.join(os.getcwd(), dir_name, step_1)
# chat_1 = converter.rawfile2chat(file_path_1)

# # print(json.dumps(chat, indent=4, ensure_ascii=False))
# print(">>> ROUND 1 <<<")
# res_1 = call_azure_api(chat_1)

# following_input = """
# [题目]
# 已知函数 $f(x)=a\left(\mathrm{e}^x+a\right)-x$.
# (1) 讨论 $f(x)$ 的单调性：
# (2) 证明：当 $a>0$ 时, $f(x)>2 \ln a+\frac{3}{2}$.

# [解题过程]
# """

# input_2 = following_input + res_1
# file_path_2 = os.path.join(os.getcwd(), dir_name, step_2)
# chat_2 = converter.rawfile2chat(file_path_2)
# chat_2.append({"role": "user", "content": input_2})
# print(">>> ROUND 2 <<<")
# res_2 = call_azure_api(chat_2)

# input_3 = following_input + res_2
# file_path_3 = os.path.join(os.getcwd(), dir_name, step_3)
# chat_3 = converter.rawfile2chat(file_path_3)
# chat_3.append({"role": "user", "content": input_3})
# print(">>> ROUND 3 <<<")
# res_3 = call_azure_api(chat_3)

# try :
# 	res_3_dict = json.loads(res_3)
# except Exception as e:
# 	print("!! Final result is not a json string.")
# 	print(e)
# 	exit(1)

# # save res_3 to ./promts/test.json
# with open(os.path.join(os.getcwd(), dir_name, "test.json"), 'w') as file:
# 	json.dump(res_3_dict, file, indent=4, ensure_ascii=False)
# 	print(f">>> Result saved to json file.")

